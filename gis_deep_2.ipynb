{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gis_deep_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0zgqAsjlxjR",
        "outputId": "cf7c52c6-37e2-47fd-a405-b3f19d698b78"
      },
      "source": [
        "%run test.ipynb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:File `'test.ipynb.py'` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GUR_86kl24a",
        "outputId": "86f71f41-d843-4cb8-a49f-6cf79e6dcd51"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data()\n",
        "print(train_X.shape)\n",
        "print(train_Y.shape)\n",
        "print(test_X.shape)\n",
        "print(test_Y.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "2KNABblhl-oO",
        "outputId": "479e2f54-e39b-4acf-b161-7f2be7387767"
      },
      "source": [
        "plt.imshow(train_X[10], cmap = 'pink')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMDw0G8pmVP3",
        "outputId": "c9a75c3b-a807-4f29-f31f-8213703202e5"
      },
      "source": [
        "print(train_X[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0  11 142 200 106   0   0   0   0   0   0   0\n",
            "   85 185 112   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 152 214 217 194 236 216 187 149 135 153 211 217\n",
            "  231 205 217 188  34   0   0   0   0   0]\n",
            " [  0   0   0   0   0  66 185 166 180 181 190 211 221 197 146 198 206 191\n",
            "  168 190 172 188 175   0   0   0   0   0]\n",
            " [  0   0   0   0   0 135 153 160 175 180 170 186 187 190 188 190 187 174\n",
            "  195 185 174 161 175  59   0   0   0   0]\n",
            " [  0   0   0   0   0 161 147 160 170 178 177 180 168 173 174 171 185 184\n",
            "  185 172 171 164 174 120   0   0   0   0]\n",
            " [  0   0   0   0   2 175 146 145 168 178 181 185 180 184 178 179 187 191\n",
            "  193 190 181 171 172 158   0   0   0   0]\n",
            " [  0   0   0   0  35 177 155 140 151 172 191 187 186 187 186 187 182 191\n",
            "  194 188 180 161 161 185   0   0   0   0]\n",
            " [  0   0   0   0  59 170 153 141 120 154 160 161 172 168 166 161 165 172\n",
            "  170 164 139 149 162 166  21   0   0   0]\n",
            " [  0   0   0   0  79 145 160 214 123 128 153 160 164 158 157 154 155 170\n",
            "  165 141 195 193 152 166  61   0   0   0]\n",
            " [  0   0   0   0 100 157 225 245 175 113 174 158 158 160 155 160 164 178\n",
            "  188 135 185 240 201 172 108   0   0   0]\n",
            " [  0   0   0   0   0  31 174  28 126 153 166 152 158 158 160 161 157 168\n",
            "  191 188  18 132 159   7   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  82 187 159 153 157 158 162 164 164 154\n",
            "  187 190   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   1   3   5   0  37 175 158 155 162 158 160 162 165 153\n",
            "  177 205   0   0   3   3   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1   0  25 175 152 160 158 161 160 164 164 161\n",
            "  166 200   0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   4   0  30 171 147 164 155 165 161 165 162 170\n",
            "  164 162   0   0   2   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   4   0  57 166 155 164 166 161 161 164 167 165\n",
            "  165 162  28   0   3   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   3   0 114 161 161 166 159 168 161 161 172 162\n",
            "  165 171  50   0   5   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1   0 149 157 167 172 159 172 164 161 172 170\n",
            "  160 171  89   0   4   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   4 171 164 166 173 159 179 166 160 174 167\n",
            "  162 166 128   0   2   0   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0  18 152 173 160 179 154 181 166 164 175 170\n",
            "  166 170 164   0   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   4   0  47 165 172 167 185 153 187 173 165 174 179\n",
            "  166 166 158   5   0   3   0   0   0   0]\n",
            " [  0   0   0   0   0   4   0  87 180 162 179 179 157 191 182 165 168 190\n",
            "  173 165 166  20   0   4   0   0   0   0]\n",
            " [  0   0   0   0   0   4   0 105 187 157 194 175 161 190 184 170 158 205\n",
            "  177 168 171  44   0   4   0   0   0   0]\n",
            " [  0   0   0   0   0   5   0 138 181 158 205 160 167 190 198 167 152 218\n",
            "  186 170 172  57   0   5   0   0   0   0]\n",
            " [  0   0   0   0   0   5   0 135 174 167 199 155 166 201 219 165 158 218\n",
            "  188 167 175  56   0   7   0   0   0   0]\n",
            " [  0   0   0   0   0   5   0 129 171 172 177 153 159 206 216 148 157 206\n",
            "  190 165 175  48   0   5   0   0   0   0]\n",
            " [  0   0   0   0   0   5   0 167 187 182 198 194 200 226 240 184 206 255\n",
            "  197 178 179  42   0   5   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0 115 135 113 106  85  82 108 133  83  90 121\n",
            "  120 110 158  18   0   3   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhvOUgy5m7WY",
        "outputId": "5659d67b-b24e-4fdd-c26f-ffa28a4b1433"
      },
      "source": [
        "print(\"train_X[10].shape : \", train_X[10].shape)\n",
        "print(\"train_X[10].ndim : \", train_X[10].ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_X[10].shape :  (28, 28)\n",
            "train_X[10].ndim :  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMjisPoUnEHS",
        "outputId": "75ea66b2-65d9-410a-e6d2-0de9d4ffa12f"
      },
      "source": [
        "train_X_flat = train_X[10].flatten()\n",
        "# flatten을 해주는 이유가 뭐더라?\n",
        "print(\"train_X_flat.shape : \", train_X_flat.shape)\n",
        "print(\"train_X_flat.ndim : \", train_X_flat.ndim)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_X_flat.shape :  (784,)\n",
            "train_X_flat.ndim :  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D48FORQXnQcA",
        "outputId": "fdaa4c40-0a54-4b06-8939-61d581bebb6d"
      },
      "source": [
        "input_cnt = len(train_X_flat)            #독립변수\n",
        "output_cnt = len(set(train_Y))           #종속변수\n",
        "RND_MEAN = 0\n",
        "RND_STD = 1\n",
        "weight = np.random.normal(RND_MEAN,RND_STD,size = [input_cnt,output_cnt])\n",
        "bias = np.random.normal(RND_MEAN,RND_STD,size = [output_cnt])\n",
        "\n",
        "parameter = {'w' : weight, 'b' : bias}\n",
        "\n",
        "print(\"parameter['w'].shape : \",parameter['w'].shape)\n",
        "print(\"parameter['w'].ndim : \",parameter['w'].ndim)\n",
        "\n",
        "print(\"parameter['b'].shape : \",parameter['b'].shape)\n",
        "print(\"parameter['b'].ndim : \",parameter['b'].ndim)\n",
        "print(\"=================================================================\")\n",
        "\n",
        "df_w = pd.DataFrame(parameter['w'],\n",
        "                    columns=['w1','w2','w3','w4','w5','w6','w7','w8','w9','w10'])\n",
        "df_b = pd.DataFrame(parameter['b'],\n",
        "                    columns = ['b'])\n",
        "df_x = pd.DataFrame(train_X_flat, columns= ['input_data'])\n",
        "\n",
        "df_data = pd.concat([df_x, df_w, df_b],axis = 1)\n",
        "\n",
        "y_hat_1 = np.matmul(df_data['input_data'],df_data['w1']) + df_data['b'][0]\n",
        "y_hat_2 = np.matmul(df_data['input_data'],df_data['w2']) + df_data['b'][1]\n",
        "y_hat_3 = np.matmul(df_data['input_data'],df_data['w3']) + df_data['b'][2]\n",
        "y_hat_4 = np.matmul(df_data['input_data'],df_data['w4']) + df_data['b'][3]\n",
        "y_hat_5 = np.matmul(df_data['input_data'],df_data['w5']) + df_data['b'][4]\n",
        "y_hat_6 = np.matmul(df_data['input_data'],df_data['w6']) + df_data['b'][5]\n",
        "y_hat_7 = np.matmul(df_data['input_data'],df_data['w7']) + df_data['b'][6]\n",
        "y_hat_8 = np.matmul(df_data['input_data'],df_data['w8']) + df_data['b'][7]\n",
        "y_hat_9 = np.matmul(df_data['input_data'],df_data['w9']) + df_data['b'][8]\n",
        "y_hat_10 = np.matmul(df_data['input_data'],df_data['w10']) + df_data['b'][9]\n",
        "\n",
        "y_hat_total = np.matmul(df_data['input_data'], parameter['w']) + parameter['b']\n",
        "np.exp(y_hat_total)\n",
        "f_mnist_max = np.max(y_hat_total)\n",
        "\n",
        "diff_y_hat_row = []\n",
        "for i in range(len(y_hat_total)):\n",
        "    diff_y_hat = y_hat_total[i] - f_mnist_max\n",
        "    diff_y_hat_row.append(diff_y_hat)\n",
        "print(\"diff_y_hat_row : \\n\", diff_y_hat_row)\n",
        "print(\"==========================================================\")\n",
        "\n",
        "exp_y_hat_row = []\n",
        "for i in range(len(diff_y_hat_row)):\n",
        "    exp_y_hat = np.exp(diff_y_hat_row[i])\n",
        "    exp_y_hat_row.append(exp_y_hat)\n",
        "print(\"exp_y_hat_row : \\n\",exp_y_hat_row)\n",
        "print(\"==========================================================\")\n",
        "\n",
        "exp_i_sum = np.sum(exp_y_hat_row)\n",
        "result = []\n",
        "\n",
        "for i in range(len(exp_y_hat_row)):\n",
        "    result.append(exp_y_hat_row[i]/exp_i_sum)\n",
        "\n",
        "result = np.round(result,3)\n",
        "\n",
        "for i in range(len(result)):\n",
        "    print(\"Label {} : {} %\".format(i, result[i] * 100))\n",
        "print(\"==========================================================\")\n",
        "print(\"Result Predict - {} label\".format(np.argmax(result)))\n",
        "print(\"Y_Label : \", train_Y[10])\n",
        "print(\"Total % : {}%\".format(np.round(np.sum(result) * 100 ,2)))\n",
        "print(\"==========================================================\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "parameter['w'].shape :  (784, 10)\n",
            "parameter['w'].ndim :  2\n",
            "parameter['b'].shape :  (10,)\n",
            "parameter['b'].ndim :  1\n",
            "=================================================================\n",
            "diff_y_hat_row : \n",
            " [-15750.69153291882, -9793.05736394997, -14408.774138872977, -11436.32815422116, -9270.91014737945, -7247.539348920266, -7201.93147246091, 0.0, -8709.058915683829, -11523.617537530075]\n",
            "==========================================================\n",
            "exp_y_hat_row : \n",
            " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
            "==========================================================\n",
            "Label 0 : 0.0 %\n",
            "Label 1 : 0.0 %\n",
            "Label 2 : 0.0 %\n",
            "Label 3 : 0.0 %\n",
            "Label 4 : 0.0 %\n",
            "Label 5 : 0.0 %\n",
            "Label 6 : 0.0 %\n",
            "Label 7 : 100.0 %\n",
            "Label 8 : 0.0 %\n",
            "Label 9 : 0.0 %\n",
            "==========================================================\n",
            "Result Predict - 7 label\n",
            "Y_Label :  0\n",
            "Total % : 100.0%\n",
            "==========================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "IH_AS36-nwWc",
        "outputId": "1aca58dc-b8a1-4033-b1e1-737d5244e3da"
      },
      "source": [
        "df_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_data</th>\n",
              "      <th>w1</th>\n",
              "      <th>w2</th>\n",
              "      <th>w3</th>\n",
              "      <th>w4</th>\n",
              "      <th>w5</th>\n",
              "      <th>w6</th>\n",
              "      <th>w7</th>\n",
              "      <th>w8</th>\n",
              "      <th>w9</th>\n",
              "      <th>w10</th>\n",
              "      <th>b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.796383</td>\n",
              "      <td>-0.124280</td>\n",
              "      <td>-1.209282</td>\n",
              "      <td>0.519206</td>\n",
              "      <td>-0.410066</td>\n",
              "      <td>-1.130013</td>\n",
              "      <td>-1.517912</td>\n",
              "      <td>-1.357773</td>\n",
              "      <td>-0.296948</td>\n",
              "      <td>0.224674</td>\n",
              "      <td>0.385317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.568989</td>\n",
              "      <td>-0.373942</td>\n",
              "      <td>-0.359312</td>\n",
              "      <td>0.316106</td>\n",
              "      <td>2.104777</td>\n",
              "      <td>-0.971129</td>\n",
              "      <td>-0.387224</td>\n",
              "      <td>0.345566</td>\n",
              "      <td>-0.314498</td>\n",
              "      <td>0.844996</td>\n",
              "      <td>-1.226003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.211865</td>\n",
              "      <td>0.894542</td>\n",
              "      <td>-0.170066</td>\n",
              "      <td>0.118994</td>\n",
              "      <td>-1.153007</td>\n",
              "      <td>-0.149580</td>\n",
              "      <td>-0.604831</td>\n",
              "      <td>0.808186</td>\n",
              "      <td>-1.406405</td>\n",
              "      <td>0.518307</td>\n",
              "      <td>1.018751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.303473</td>\n",
              "      <td>-0.054418</td>\n",
              "      <td>-0.528903</td>\n",
              "      <td>1.111420</td>\n",
              "      <td>0.298749</td>\n",
              "      <td>-2.444934</td>\n",
              "      <td>0.228846</td>\n",
              "      <td>-1.501724</td>\n",
              "      <td>-2.283122</td>\n",
              "      <td>-0.421033</td>\n",
              "      <td>-0.961263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.763958</td>\n",
              "      <td>-0.140143</td>\n",
              "      <td>-0.407843</td>\n",
              "      <td>0.715037</td>\n",
              "      <td>0.519563</td>\n",
              "      <td>-0.489937</td>\n",
              "      <td>1.331801</td>\n",
              "      <td>0.149922</td>\n",
              "      <td>-0.530081</td>\n",
              "      <td>0.087111</td>\n",
              "      <td>1.924924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.420840</td>\n",
              "      <td>1.246961</td>\n",
              "      <td>-0.435832</td>\n",
              "      <td>0.272333</td>\n",
              "      <td>-0.794621</td>\n",
              "      <td>-0.803170</td>\n",
              "      <td>-0.145529</td>\n",
              "      <td>0.436515</td>\n",
              "      <td>-1.190566</td>\n",
              "      <td>-0.198757</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>780</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.562005</td>\n",
              "      <td>0.556694</td>\n",
              "      <td>0.769470</td>\n",
              "      <td>0.082830</td>\n",
              "      <td>0.285829</td>\n",
              "      <td>-0.103945</td>\n",
              "      <td>0.230251</td>\n",
              "      <td>-1.096563</td>\n",
              "      <td>1.496068</td>\n",
              "      <td>1.286530</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781</th>\n",
              "      <td>0</td>\n",
              "      <td>1.555932</td>\n",
              "      <td>3.460199</td>\n",
              "      <td>0.733423</td>\n",
              "      <td>0.033148</td>\n",
              "      <td>-0.920553</td>\n",
              "      <td>-0.999101</td>\n",
              "      <td>0.170343</td>\n",
              "      <td>-0.683289</td>\n",
              "      <td>0.060548</td>\n",
              "      <td>0.903070</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>0</td>\n",
              "      <td>0.088035</td>\n",
              "      <td>-3.016495</td>\n",
              "      <td>-0.277975</td>\n",
              "      <td>-0.403808</td>\n",
              "      <td>-0.825037</td>\n",
              "      <td>2.450911</td>\n",
              "      <td>0.279754</td>\n",
              "      <td>0.827029</td>\n",
              "      <td>0.634375</td>\n",
              "      <td>-1.292203</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783</th>\n",
              "      <td>0</td>\n",
              "      <td>0.202604</td>\n",
              "      <td>-2.969654</td>\n",
              "      <td>-1.904236</td>\n",
              "      <td>-0.216784</td>\n",
              "      <td>0.292169</td>\n",
              "      <td>0.525397</td>\n",
              "      <td>-0.835385</td>\n",
              "      <td>0.984925</td>\n",
              "      <td>-1.049694</td>\n",
              "      <td>-1.411006</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>784 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     input_data        w1        w2  ...        w9       w10         b\n",
              "0             0  0.796383 -0.124280  ... -0.296948  0.224674  0.385317\n",
              "1             0 -0.568989 -0.373942  ... -0.314498  0.844996 -1.226003\n",
              "2             0  0.211865  0.894542  ... -1.406405  0.518307  1.018751\n",
              "3             0 -0.303473 -0.054418  ... -2.283122 -0.421033 -0.961263\n",
              "4             0  0.763958 -0.140143  ... -0.530081  0.087111  1.924924\n",
              "..          ...       ...       ...  ...       ...       ...       ...\n",
              "779           3 -0.420840  1.246961  ... -1.190566 -0.198757       NaN\n",
              "780           0 -1.562005  0.556694  ...  1.496068  1.286530       NaN\n",
              "781           0  1.555932  3.460199  ...  0.060548  0.903070       NaN\n",
              "782           0  0.088035 -3.016495  ...  0.634375 -1.292203       NaN\n",
              "783           0  0.202604 -2.969654  ... -1.049694 -1.411006       NaN\n",
              "\n",
              "[784 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stmnwdLboD_R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}